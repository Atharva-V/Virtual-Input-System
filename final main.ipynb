{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from handtracker.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import handtracker as htm\n",
    "import time\n",
    "import autopy\n",
    "import numpy as np\n",
    "impo2rt cv\n",
    "import copy\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n",
    "import math\n",
    "from pynput.keyboard import Key, Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "        # convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 26)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Adding sequence of convolutional and max pooling layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 3 * 3)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def get_histogram(frame):\n",
    "    roi1 = frame[rect1_tl[1]:rect1_tl[1] + width, rect1_tl[0]:rect1_tl[0] + height]\n",
    "    roi2 = frame[rect2_tl[1]:rect2_tl[1] + width, rect2_tl[0]:rect2_tl[0] + height]\n",
    "    roi3 = frame[rect3_tl[1]:rect3_tl[1] + width, rect3_tl[0]:rect3_tl[0] + height]\n",
    "    roi4 = frame[rect4_tl[1]:rect4_tl[1] + width, rect4_tl[0]:rect4_tl[0] + height]\n",
    "    roi5 = frame[rect5_tl[1]:rect5_tl[1] + width, rect5_tl[0]:rect5_tl[0] + height]\n",
    "    roi = np.concatenate((roi1, roi2, roi3, roi4, roi5), axis=0)\n",
    "    roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    return cv2.calcHist([roi_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "\n",
    "def get_ROI(canvas):\n",
    "    gray = cv2.bitwise_not(canvas)\n",
    "    ret, thresh = cv2.threshold(gray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "    ctrs, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    areas = []\n",
    "    for i in range(len(ctrs)):\n",
    "        x, y, w, h = cv2.boundingRect(ctrs[i])\n",
    "        areas.append((w * h, i))\n",
    "\n",
    "    def sort_second(val):\n",
    "        return val[0]\n",
    "    areas.sort(key=sort_second, reverse=True)\n",
    "    x, y, w, h = cv2.boundingRect(ctrs[areas[1][1]])\n",
    "    cv2.rectangle(canvas, (x, y), (x + w, y + h), (255, 255, 0), 1)\n",
    "    roi = gray[y:y + h, x:x + w]\n",
    "    return roi\n",
    "\n",
    "def character_prediction(roi, model):\n",
    "    \"\"\"Predicts character written with image processing\"\"\"\n",
    "    img = cv2.resize(roi, (28, 28))\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.5, 0.5, 0.5],\n",
    "        std=[0.5, 0.5, 0.5]\n",
    "    )\n",
    "    preprocess = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    p_img = preprocess(img)\n",
    "\n",
    "    model.eval()\n",
    "    p_img = p_img.reshape([1, 1, 28, 28]).float()\n",
    "    output = model(torch.transpose(p_img, 2, 3))\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "wCam, hCam = 640, 480\n",
    "frameR = 100 # Frame Reduction\n",
    "smoothening = 7\n",
    "#########################\n",
    "\n",
    "pTime = 0\n",
    "plocX, plocY = 0, 0\n",
    "clocX, clocY = 0, 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, wCam)\n",
    "cap.set(4, hCam)\n",
    "detector = htm.handDetector(maxHands=1)\n",
    "wScr, hScr = autopy.screen.size()\n",
    "# print(wScr, hScr)\n",
    "\n",
    "canvas = np.zeros((720, 1280), np.uint8)\n",
    "far_points = []\n",
    "model = Cnn()\n",
    "model.load_state_dict(torch.load('model_emnist.pt', map_location='cpu'))\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "prediction= 0\n",
    "while True:\n",
    "    try:\n",
    "        # 1. Find hand Landmarks\n",
    "        success, img = cap.read()\n",
    "        img = detector.findHands(img)\n",
    "        lmList, bbox = detector.findPosition(img)\n",
    "        # 2. Get the tip of the index and middle fingers\n",
    "        if len(lmList) != 0:\n",
    "            x1, y1 = lmList[8][1:]\n",
    "            x2, y2 = lmList[12][1:]\n",
    "            # print(x1, y1, x2, y2)\n",
    "        if len(lmList) != 0:\n",
    "            #print(lmList[8][1:])\n",
    "            #far = lmList[8][1:]\n",
    "            far = (lmList[8][1],lmList[8][2])\n",
    "        canvas[:, :] = 255\n",
    "\n",
    "        # 3. Check which fingers are up\n",
    "        fingers = detector.fingersUp()\n",
    "\n",
    "        # 4. Only Index Finger : Moving Mode\n",
    "        if fingers[1] == 1 and fingers[2] == 0 and fingers[3] == 0:\n",
    "            cv2.putText(img,\"Moving Mode\", (100, 45), font, 1,(255, 255, 255), 2, cv2.LINE_AA)\n",
    "            # 5. Convert Coordinates\n",
    "            x3 = np.interp(x1, (frameR, wCam - frameR), (0, wScr))\n",
    "            y3 = np.interp(y1, (frameR, hCam - frameR), (0, hScr))\n",
    "            # 6. Smoothen Values\n",
    "            clocX = plocX + (x3 - plocX) / smoothening\n",
    "            clocY = plocY + (y3 - plocY) / smoothening\n",
    "\n",
    "            # 7. Move Mouse\n",
    "            autopy.mouse.move(wScr - clocX, clocY)\n",
    "            cv2.circle(img, (x1, y1), 15, (255, 0, 255), cv2.FILLED)\n",
    "            plocX, plocY = clocX, clocY\n",
    "\n",
    "        # 8. Both Index and middle fingers are up : Clicking Mode\n",
    "        if fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 0:\n",
    "            cv2.putText(img,\"Clicking Mode\", (100, 45), font, 1,(255, 255, 255), 2, cv2.LINE_AA)\n",
    "            # 9. Find distance between fingers\n",
    "            length, img, lineInfo = detector.findDistance(8, 12, img)\n",
    "            # 10. Click mouse if distance short\n",
    "            if length < 30:\n",
    "                cv2.circle(img, (lineInfo[4], lineInfo[5]),\n",
    "                15, (0, 255, 0), cv2.FILLED)\n",
    "                autopy.mouse.click()\n",
    "\n",
    "        if fingers[1] == 1 and fingers[2] == 1 and fingers[3] == 1:\n",
    "            cv2.putText(img,\"Character Written: \" + chr(prediction + 65), (8, 80), font, 1,(255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(img,\"Drawing Mode\", (100, 45), font, 1,(255, 255, 255), 2, cv2.LINE_AA)\n",
    "            if len(far_points) > 100:\n",
    "                far_points.pop(0)\n",
    "            far_points.append(far)\n",
    "            #print(far_points)\n",
    "            for i in range(len(far_points) - 1):\n",
    "                cv2.line(img, far_points[i], far_points[i + 1], (255, 5, 255), 20)\n",
    "                cv2.line(canvas, far_points[i], far_points[i + 1], (0, 0, 0), 20)\n",
    "                \n",
    "            length, img, lineInfo = detector.findDistance(4, 20, img)\n",
    "            if length < 30:\n",
    "                # Prediction\n",
    "                #cv2.circle(img, (lineInfo[4], lineInfo[5]),15, (0, 255, 0), cv2.FILLED)\n",
    "                roi = get_ROI(canvas)\n",
    "                #print(roi)\n",
    "                prediction = character_prediction(roi, model)\n",
    "                #print(prediction)\n",
    "                name = str(prediction) + '.jpg'\n",
    "                cv2.imwrite(name, roi)\n",
    "                \n",
    "#                 cv2.putText(img,\"Character Written: \" + chr(prediction + 65), (8, 250), font, 1,\n",
    "#                         (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                canvas[:, :] = 255\n",
    "                far_points.clear()\n",
    "                cv2.waitKey(500)\n",
    "                keyboard = Controller()\n",
    "                key = chr(prediction + 65)\n",
    "                keyboard.press(key)\n",
    "                keyboard.release(key)\n",
    "                #print(chr(prediction + 65))\n",
    "                \n",
    "        if fingers[0] == 0 and fingers[1] == 0 and fingers[2] == 0 and fingers[3] == 0 and fingers[4] == 0:\n",
    "            canvas[:, :] = 255\n",
    "            far_points.clear()\n",
    "            cv2.waitKey(500)\n",
    "            \n",
    "                \n",
    "        # 11. Frame Rate\n",
    "        cTime = time.time()\n",
    "        fps = 1 / (cTime - pTime)\n",
    "        pTime = cTime\n",
    "        cv2.putText(img, str(int(fps)), (30, 45), cv2.FONT_HERSHEY_PLAIN, 3,\n",
    "        (255, 0, 0), 3)\n",
    "        # 12. Display\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        cv2.waitKey(1)\n",
    "    except:continue\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
